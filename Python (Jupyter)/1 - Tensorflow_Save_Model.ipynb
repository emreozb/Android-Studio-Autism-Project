{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Group 2\n",
    "#SW550\n",
    "\n",
    "#data= pd.read_excel('Autism_Data_Child_Version-2_Clean.csv')\n",
    "dataFileName = 'Autism_Data_Child_Version-2 - Clean.csv';\n",
    "data= pd.read_csv(dataFileName)\n",
    "#data.rename(columns= {'austim':'autism'},inplace = True)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Data to numeric values\n",
    "data= data.fillna(method='ffill')\n",
    "data['Sex']=data['Sex'].map({'m': 0, 'f': 1})\n",
    "data['Ethnicity']=data['Ethnicity'].map({\n",
    "    'aboriginal': 0,\n",
    "    'asian': 1,\n",
    "    'black': 2, \n",
    "    'hispanic': 3,\n",
    "    'latino': 4,\n",
    "    'middle eastern': 5,\n",
    "    'south asians': 6,\n",
    "    'white': 7,\n",
    "    'others': 8\n",
    "})\n",
    "data['Ethnicity'].fillna(9, inplace = True)\n",
    "\n",
    "data['Jaundice']=data['Jaundice'].map({'no': 0, 'yes': 1})\n",
    "data['Family_ASD']=data['Family_ASD'].map({'no': 0, 'yes': 1})\n",
    "data['Residence']=data['Residence'].map({\n",
    "    'Afghanistan': 0,\n",
    "    'Albania': 1,\n",
    "    'Algeria': 2,\n",
    "    'American Samoa': 3,\n",
    "    'Angola': 4,\n",
    "    'Argentina': 5,\n",
    "    'Armenia': 6,\n",
    "    'Australia': 7,\n",
    "    'Austria': 8,\n",
    "    'Bahamas': 9,\n",
    "    'Bahrain': 10,\n",
    "    'Bangladesh': 11,\n",
    "    'Belgium': 12,\n",
    "    'Belize': 13,\n",
    "    'Bhutan': 14,\n",
    "    'Bolivia': 15,\n",
    "    'Brazil': 16,\n",
    "    'British Indian Ocean Territory': 17,\n",
    "    'Bulgaria': 18,\n",
    "    'Canada': 19,\n",
    "    'Chile': 20,\n",
    "    'China': 21,\n",
    "    'Costa Rica': 22,\n",
    "    'Dominican Republic': 23,\n",
    "    'Egypt': 24,\n",
    "    'Europe': 25,\n",
    "    'Finland': 26,\n",
    "    'Georgia': 27,\n",
    "    'Germany': 28,\n",
    "    'Ghana': 29,\n",
    "    'Hungary': 30,\n",
    "    'India': 31,\n",
    "    'Iran': 32,\n",
    "    'Iraq': 33,\n",
    "    'Ireland': 34,\n",
    "    'Isle of Man': 35,\n",
    "    'Italy': 36,\n",
    "    'Jamaica': 37,\n",
    "    'Japan': 38,\n",
    "    'Jordan': 39,\n",
    "    'Kuwait': 40,\n",
    "    'Latvia': 41,\n",
    "    'Lebanon': 42,\n",
    "    'Libya': 43,\n",
    "    'Malaysia': 44,\n",
    "    'Malta': 45,\n",
    "    'Mexico': 46,\n",
    "    'Nepal': 47,\n",
    "    'Netherlands': 48,\n",
    "    'New Zealand': 49,\n",
    "    'Nigeria': 50,\n",
    "    'Oman': 51,\n",
    "    'Pakistan': 52,\n",
    "    'Peru': 53,\n",
    "    'Philippines': 54,\n",
    "    'Qatar': 55,\n",
    "    'Romania': 56,\n",
    "    'Russia': 57,\n",
    "    'Saudi Arabia': 58,\n",
    "    'South Africa': 59,\n",
    "    'South Korea': 60,\n",
    "    'Sri Lanka': 61,\n",
    "    'Sudan': 62,\n",
    "    'Sweden': 63,\n",
    "    'Syria': 64,\n",
    "    'Turkey': 65,\n",
    "    'U.S. Outlying Islands': 66,\n",
    "    'United Arab Emirates': 67,\n",
    "    'United Kingdom': 68,\n",
    "    'United States': 69,\n",
    "    'Uzbekistan': 70,\n",
    "    'Virgin Islands, British': 71\n",
    "})\n",
    "data['Used_App_Before']=data['Used_App_Before'].map({'no': 0, 'yes': 1})\n",
    "data['Language']=data['Language'].map({\n",
    "    'arabic': 0,\n",
    "    'english': 1,\n",
    "    'french': 2,\n",
    "    'mandarin': 3,\n",
    "    'portuguese': 4,\n",
    "    'russian': 5,\n",
    "    'spanish': 6,\n",
    "    'swahili': 7,\n",
    "    'turkish': 8,\n",
    "    'urdu': 9\n",
    "})\n",
    "data['User']=data['User'].map({\n",
    "    'friend': 0,\n",
    "    'health care professional': 1,\n",
    "    'parent': 2,\n",
    "    'relative': 3,\n",
    "    'self': 4,\n",
    "    'teacher': 5\n",
    "})\n",
    "data['Class']=data['Class'].map({'NO': 0, 'YES': 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.head()\n",
    "# Export cleaned data to CSV to compare\n",
    "df = pd.DataFrame(data, columns= [\n",
    "    'A1',\n",
    "    'A2',\n",
    "    'A3',\n",
    "    'A4',\n",
    "    'A5',\n",
    "    'A6',\n",
    "    'A7',\n",
    "    'A8',\n",
    "    'A9',\n",
    "    'A10',\n",
    "    'Age',\n",
    "    'Sex',\n",
    "    'Ethnicity',\n",
    "    'Jaundice',\n",
    "    'Family_ASD',\n",
    "    'Residence',\n",
    "    'Used_App_Before',\n",
    "    'Language',\n",
    "    'User',\n",
    "    'Class'\n",
    "])\n",
    "df.to_csv(r'mappedData.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Jaundice</th>\n",
       "      <th>Family_ASD</th>\n",
       "      <th>Residence</th>\n",
       "      <th>Used_App_Before</th>\n",
       "      <th>Language</th>\n",
       "      <th>User</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>509 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  Age  Sex  Ethnicity  Jaundice  \\\n",
       "0     0   1   1   0   0   1   1   0   0    1    4    0        5.0         1   \n",
       "1     0   1   1   1   1   1   1   0   0    1    4    0        5.0         1   \n",
       "2     0   1   1   1   1   1   0   1   1    1    5    0        7.0         0   \n",
       "3     0   1   1   0   1   1   1   0   0    0    4    0        5.0         1   \n",
       "4     0   0   1   1   1   1   0   1   0    1    5    0        7.0         0   \n",
       "..   ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...        ...       ...   \n",
       "504   1   1   1   1   1   1   1   0   1    1    9    0        3.0         0   \n",
       "505   1   0   1   0   1   1   1   1   0    1    9    0        7.0         0   \n",
       "506   1   1   1   1   0   1   0   0   1    1    5    0        5.0         0   \n",
       "507   1   1   1   0   0   1   0   1   1    1    4    1        1.0         0   \n",
       "508   1   1   1   0   1   1   0   0   0    1    5    0        7.0         1   \n",
       "\n",
       "     Family_ASD  Residence  Used_App_Before  Language  User  Class  \n",
       "0             0         43                0         0     2      0  \n",
       "1             0         43                1         0     2      1  \n",
       "2             0         57                0         5     2      1  \n",
       "3             0         43                0         0     2      0  \n",
       "4             0         57                0         5     2      0  \n",
       "..          ...        ...              ...       ...   ...    ...  \n",
       "504           0         69                0         1     2      1  \n",
       "505           0         71                0         1     2      1  \n",
       "506           1         39                0         0     2      1  \n",
       "507           0         68                0         1     2      1  \n",
       "508           1         68                0         1     2      0  \n",
       "\n",
       "[509 rows x 20 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Class', axis = 1).values\n",
    "y = data['Class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train, y_test = train_test_split(X, y, train_size = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create model and fit data to it\n",
    "model = Sequential()\n",
    "\n",
    "# Input Layer\n",
    "model.add(Dense(19, input_shape=(19,), activation = 'relu'))\n",
    "\n",
    "# Hidden Layers\n",
    "model.add(Dense(38, activation = 'relu'))\n",
    "model.add(Dense(38, activation = 'relu'))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 407 samples, validate on 102 samples\n",
      "Epoch 1/200\n",
      "407/407 [==============================] - 2s 4ms/sample - loss: 0.6588 - accuracy: 0.5528 - val_loss: 0.6133 - val_accuracy: 0.6176\n",
      "Epoch 2/200\n",
      "407/407 [==============================] - 0s 163us/sample - loss: 0.6075 - accuracy: 0.6609 - val_loss: 0.5601 - val_accuracy: 0.7059\n",
      "Epoch 3/200\n",
      "407/407 [==============================] - 0s 156us/sample - loss: 0.5559 - accuracy: 0.7248 - val_loss: 0.4999 - val_accuracy: 0.7843\n",
      "Epoch 4/200\n",
      "407/407 [==============================] - 0s 155us/sample - loss: 0.4902 - accuracy: 0.8305 - val_loss: 0.4312 - val_accuracy: 0.8431\n",
      "Epoch 5/200\n",
      "407/407 [==============================] - 0s 156us/sample - loss: 0.4192 - accuracy: 0.8722 - val_loss: 0.3609 - val_accuracy: 0.9118\n",
      "Epoch 6/200\n",
      "407/407 [==============================] - 0s 160us/sample - loss: 0.3491 - accuracy: 0.8722 - val_loss: 0.3018 - val_accuracy: 0.9020\n",
      "Epoch 7/200\n",
      "407/407 [==============================] - 0s 158us/sample - loss: 0.2932 - accuracy: 0.8968 - val_loss: 0.2547 - val_accuracy: 0.9118\n",
      "Epoch 8/200\n",
      "407/407 [==============================] - 0s 159us/sample - loss: 0.2495 - accuracy: 0.9140 - val_loss: 0.2189 - val_accuracy: 0.9216\n",
      "Epoch 9/200\n",
      "407/407 [==============================] - 0s 165us/sample - loss: 0.2166 - accuracy: 0.9115 - val_loss: 0.1898 - val_accuracy: 0.9216\n",
      "Epoch 10/200\n",
      "407/407 [==============================] - 0s 171us/sample - loss: 0.1907 - accuracy: 0.9312 - val_loss: 0.1648 - val_accuracy: 0.9314\n",
      "Epoch 11/200\n",
      "407/407 [==============================] - 0s 162us/sample - loss: 0.1689 - accuracy: 0.9312 - val_loss: 0.1451 - val_accuracy: 0.9412\n",
      "Epoch 12/200\n",
      "407/407 [==============================] - 0s 267us/sample - loss: 0.1525 - accuracy: 0.9410 - val_loss: 0.1312 - val_accuracy: 0.9412\n",
      "Epoch 13/200\n",
      "407/407 [==============================] - 0s 261us/sample - loss: 0.1434 - accuracy: 0.9484 - val_loss: 0.1301 - val_accuracy: 0.9412\n",
      "Epoch 14/200\n",
      "407/407 [==============================] - 0s 275us/sample - loss: 0.1310 - accuracy: 0.9558 - val_loss: 0.1076 - val_accuracy: 0.9608\n",
      "Epoch 15/200\n",
      "407/407 [==============================] - 0s 312us/sample - loss: 0.1220 - accuracy: 0.9582 - val_loss: 0.0979 - val_accuracy: 0.9706\n",
      "Epoch 16/200\n",
      "407/407 [==============================] - 0s 294us/sample - loss: 0.1111 - accuracy: 0.9681 - val_loss: 0.0931 - val_accuracy: 0.9902\n",
      "Epoch 17/200\n",
      "407/407 [==============================] - 0s 283us/sample - loss: 0.0962 - accuracy: 0.9730 - val_loss: 0.0849 - val_accuracy: 0.9804\n",
      "Epoch 18/200\n",
      "407/407 [==============================] - 0s 279us/sample - loss: 0.0887 - accuracy: 0.9779 - val_loss: 0.0793 - val_accuracy: 0.9902\n",
      "Epoch 19/200\n",
      "407/407 [==============================] - 0s 270us/sample - loss: 0.0873 - accuracy: 0.9803 - val_loss: 0.0964 - val_accuracy: 0.9608\n",
      "Epoch 20/200\n",
      "407/407 [==============================] - 0s 257us/sample - loss: 0.0788 - accuracy: 0.9754 - val_loss: 0.0781 - val_accuracy: 0.9706\n",
      "Epoch 21/200\n",
      "407/407 [==============================] - 0s 260us/sample - loss: 0.0721 - accuracy: 0.9853 - val_loss: 0.0793 - val_accuracy: 0.9706\n",
      "Epoch 22/200\n",
      "407/407 [==============================] - 0s 245us/sample - loss: 0.0647 - accuracy: 0.9877 - val_loss: 0.0646 - val_accuracy: 0.9706\n",
      "Epoch 23/200\n",
      "407/407 [==============================] - 0s 260us/sample - loss: 0.0615 - accuracy: 0.9853 - val_loss: 0.0685 - val_accuracy: 0.9902\n",
      "Epoch 24/200\n",
      "407/407 [==============================] - 0s 259us/sample - loss: 0.0570 - accuracy: 0.9877 - val_loss: 0.0620 - val_accuracy: 0.9902\n",
      "Epoch 25/200\n",
      "407/407 [==============================] - 0s 242us/sample - loss: 0.0579 - accuracy: 0.9853 - val_loss: 0.0600 - val_accuracy: 0.9804\n",
      "Epoch 26/200\n",
      "407/407 [==============================] - 0s 259us/sample - loss: 0.0492 - accuracy: 0.9951 - val_loss: 0.0598 - val_accuracy: 0.9902\n",
      "Epoch 27/200\n",
      "407/407 [==============================] - 0s 243us/sample - loss: 0.0446 - accuracy: 0.9951 - val_loss: 0.0578 - val_accuracy: 0.9902\n",
      "Epoch 28/200\n",
      "407/407 [==============================] - 0s 259us/sample - loss: 0.0410 - accuracy: 0.9975 - val_loss: 0.0505 - val_accuracy: 0.9804\n",
      "Epoch 29/200\n",
      "407/407 [==============================] - 0s 246us/sample - loss: 0.0364 - accuracy: 0.9951 - val_loss: 0.0528 - val_accuracy: 0.9902\n",
      "Epoch 30/200\n",
      "407/407 [==============================] - 0s 269us/sample - loss: 0.0330 - accuracy: 0.9975 - val_loss: 0.0491 - val_accuracy: 0.9902\n",
      "Epoch 31/200\n",
      "407/407 [==============================] - 0s 266us/sample - loss: 0.0319 - accuracy: 0.9975 - val_loss: 0.0514 - val_accuracy: 0.9804\n",
      "Epoch 32/200\n",
      "407/407 [==============================] - 0s 266us/sample - loss: 0.0313 - accuracy: 0.9975 - val_loss: 0.0458 - val_accuracy: 0.9804\n",
      "Epoch 33/200\n",
      "407/407 [==============================] - 0s 164us/sample - loss: 0.0267 - accuracy: 0.9975 - val_loss: 0.0489 - val_accuracy: 0.9804\n",
      "Epoch 34/200\n",
      "407/407 [==============================] - 0s 153us/sample - loss: 0.0276 - accuracy: 0.9951 - val_loss: 0.0536 - val_accuracy: 0.9804\n",
      "Epoch 35/200\n",
      "407/407 [==============================] - 0s 276us/sample - loss: 0.0241 - accuracy: 0.9975 - val_loss: 0.0436 - val_accuracy: 0.9902\n",
      "Epoch 36/200\n",
      "407/407 [==============================] - 0s 301us/sample - loss: 0.0229 - accuracy: 0.9975 - val_loss: 0.0406 - val_accuracy: 0.9902\n",
      "Epoch 37/200\n",
      "407/407 [==============================] - 0s 264us/sample - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 0.9804\n",
      "Epoch 38/200\n",
      "407/407 [==============================] - 0s 256us/sample - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9902\n",
      "Epoch 39/200\n",
      "407/407 [==============================] - 0s 236us/sample - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9804\n",
      "Epoch 40/200\n",
      "407/407 [==============================] - 0s 252us/sample - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9902\n",
      "Epoch 41/200\n",
      "407/407 [==============================] - 0s 254us/sample - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9902\n",
      "Epoch 42/200\n",
      "407/407 [==============================] - 0s 240us/sample - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.0367 - val_accuracy: 0.9902\n",
      "Epoch 43/200\n",
      "407/407 [==============================] - 0s 230us/sample - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9902\n",
      "Epoch 44/200\n",
      "407/407 [==============================] - 0s 258us/sample - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9804\n",
      "Epoch 45/200\n",
      "407/407 [==============================] - 0s 259us/sample - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0347 - val_accuracy: 0.9804\n",
      "Epoch 46/200\n",
      "407/407 [==============================] - 0s 273us/sample - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9902\n",
      "Epoch 47/200\n",
      "407/407 [==============================] - 0s 245us/sample - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.0349 - val_accuracy: 0.9902\n",
      "Epoch 48/200\n",
      "407/407 [==============================] - 0s 243us/sample - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0365 - val_accuracy: 0.9902\n",
      "Epoch 49/200\n",
      "407/407 [==============================] - 0s 278us/sample - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0347 - val_accuracy: 0.9902\n",
      "Epoch 50/200\n",
      "407/407 [==============================] - 0s 273us/sample - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 0.9902\n",
      "Epoch 51/200\n",
      "407/407 [==============================] - 0s 273us/sample - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0355 - val_accuracy: 0.9902\n",
      "Epoch 52/200\n",
      "407/407 [==============================] - 0s 270us/sample - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0323 - val_accuracy: 0.9902\n",
      "Epoch 53/200\n",
      "407/407 [==============================] - 0s 288us/sample - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0331 - val_accuracy: 0.9902\n",
      "Epoch 54/200\n",
      "407/407 [==============================] - 0s 278us/sample - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0338 - val_accuracy: 0.9902\n",
      "Epoch 55/200\n",
      "407/407 [==============================] - 0s 250us/sample - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 0.9902\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407/407 [==============================] - 0s 260us/sample - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 0.9902\n",
      "Epoch 57/200\n",
      "407/407 [==============================] - 0s 251us/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0307 - val_accuracy: 0.9902\n",
      "Epoch 58/200\n",
      "407/407 [==============================] - 0s 244us/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 0.9902\n",
      "Epoch 59/200\n",
      "407/407 [==============================] - 0s 229us/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0290 - val_accuracy: 0.9902\n",
      "Epoch 60/200\n",
      "407/407 [==============================] - 0s 242us/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 0.9902\n",
      "Epoch 61/200\n",
      "407/407 [==============================] - 0s 243us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 0.9902\n",
      "Epoch 62/200\n",
      "407/407 [==============================] - 0s 260us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 0.9902\n",
      "Epoch 63/200\n",
      "407/407 [==============================] - 0s 245us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0319 - val_accuracy: 0.9902\n",
      "Epoch 64/200\n",
      "407/407 [==============================] - 0s 244us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 0.9804\n",
      "Epoch 65/200\n",
      "407/407 [==============================] - 0s 248us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0306 - val_accuracy: 0.9902\n",
      "Epoch 66/200\n",
      "407/407 [==============================] - 0s 245us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0265 - val_accuracy: 0.9902\n",
      "Epoch 67/200\n",
      "407/407 [==============================] - 0s 258us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0286 - val_accuracy: 0.9902\n",
      "Epoch 68/200\n",
      "407/407 [==============================] - 0s 262us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 0.9902\n",
      "Epoch 69/200\n",
      "407/407 [==============================] - 0s 252us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 0.9902\n",
      "Epoch 70/200\n",
      "407/407 [==============================] - 0s 251us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 0.9902\n",
      "Epoch 71/200\n",
      "407/407 [==============================] - 0s 261us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 0.9902\n",
      "Epoch 72/200\n",
      "407/407 [==============================] - 0s 288us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9902\n",
      "Epoch 73/200\n",
      "407/407 [==============================] - 0s 289us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0268 - val_accuracy: 0.9902\n",
      "Epoch 74/200\n",
      "407/407 [==============================] - 0s 275us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 0.9902\n",
      "Epoch 75/200\n",
      "407/407 [==============================] - 0s 270us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 0.9902\n",
      "Epoch 76/200\n",
      "407/407 [==============================] - 0s 263us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9902\n",
      "Epoch 77/200\n",
      "407/407 [==============================] - 0s 294us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 0.9902\n",
      "Epoch 78/200\n",
      "407/407 [==============================] - 0s 151us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 0.9902\n",
      "Epoch 79/200\n",
      "407/407 [==============================] - 0s 159us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 0.9902\n",
      "Epoch 80/200\n",
      "407/407 [==============================] - 0s 264us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 0.9902\n",
      "Epoch 81/200\n",
      "407/407 [==============================] - 0s 256us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 0.9902\n",
      "Epoch 82/200\n",
      "407/407 [==============================] - 0s 271us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 0.9902\n",
      "Epoch 83/200\n",
      "407/407 [==============================] - 0s 271us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0251 - val_accuracy: 0.9902\n",
      "Epoch 84/200\n",
      "407/407 [==============================] - 0s 255us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9902\n",
      "Epoch 85/200\n",
      "407/407 [==============================] - 0s 258us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9902\n",
      "Epoch 86/200\n",
      "407/407 [==============================] - 0s 286us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0259 - val_accuracy: 0.9902\n",
      "Epoch 87/200\n",
      "407/407 [==============================] - 0s 279us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 0.9902\n",
      "Epoch 88/200\n",
      "407/407 [==============================] - 0s 275us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 0.9902\n",
      "Epoch 89/200\n",
      "407/407 [==============================] - 0s 229us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9804\n",
      "Epoch 90/200\n",
      "407/407 [==============================] - 0s 249us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9902\n",
      "Epoch 91/200\n",
      "407/407 [==============================] - 0s 281us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9902\n",
      "Epoch 92/200\n",
      "407/407 [==============================] - 0s 278us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9902\n",
      "Epoch 93/200\n",
      "407/407 [==============================] - 0s 253us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9902\n",
      "Epoch 94/200\n",
      "407/407 [==============================] - 0s 233us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 0.9902\n",
      "Epoch 95/200\n",
      "407/407 [==============================] - 0s 270us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 0.9902\n",
      "Epoch 96/200\n",
      "407/407 [==============================] - 0s 272us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 0.9902\n",
      "Epoch 97/200\n",
      "407/407 [==============================] - 0s 295us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 0.9902\n",
      "Epoch 98/200\n",
      "407/407 [==============================] - 0s 282us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9902\n",
      "Epoch 99/200\n",
      "407/407 [==============================] - 0s 282us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 0.9902\n",
      "Epoch 100/200\n",
      "407/407 [==============================] - 0s 254us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0259 - val_accuracy: 0.9902\n",
      "Epoch 101/200\n",
      "407/407 [==============================] - 0s 283us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 0.9902\n",
      "Epoch 102/200\n",
      "407/407 [==============================] - 0s 285us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 0.9902\n",
      "Epoch 103/200\n",
      "407/407 [==============================] - 0s 263us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 0.9902\n",
      "Epoch 104/200\n",
      "407/407 [==============================] - 0s 251us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 0.9902\n",
      "Epoch 105/200\n",
      "407/407 [==============================] - 0s 290us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9902\n",
      "Epoch 106/200\n",
      "407/407 [==============================] - 0s 278us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 0.9902\n",
      "Epoch 107/200\n",
      "407/407 [==============================] - 0s 254us/sample - loss: 9.8070e-04 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9902\n",
      "Epoch 108/200\n",
      "407/407 [==============================] - 0s 245us/sample - loss: 9.2710e-04 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9902\n",
      "Epoch 109/200\n",
      "407/407 [==============================] - 0s 254us/sample - loss: 9.4675e-04 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 0.9902\n",
      "Epoch 110/200\n",
      "407/407 [==============================] - 0s 235us/sample - loss: 9.1682e-04 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9902\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407/407 [==============================] - 0s 227us/sample - loss: 8.9190e-04 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 0.9902\n",
      "Epoch 112/200\n",
      "407/407 [==============================] - 0s 232us/sample - loss: 8.5023e-04 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 0.9902\n",
      "Epoch 113/200\n",
      "407/407 [==============================] - 0s 251us/sample - loss: 8.5308e-04 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9902\n",
      "Epoch 114/200\n",
      "407/407 [==============================] - 0s 261us/sample - loss: 8.0654e-04 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 0.9902\n",
      "Epoch 115/200\n",
      "407/407 [==============================] - 0s 246us/sample - loss: 8.2127e-04 - accuracy: 1.0000 - val_loss: 0.0236 - val_accuracy: 0.9902\n",
      "Epoch 116/200\n",
      "407/407 [==============================] - 0s 273us/sample - loss: 7.7908e-04 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9902\n",
      "Epoch 117/200\n",
      "407/407 [==============================] - 0s 231us/sample - loss: 7.7141e-04 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 0.9902\n",
      "Epoch 118/200\n",
      "407/407 [==============================] - 0s 218us/sample - loss: 7.4512e-04 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 0.9902\n",
      "Epoch 119/200\n",
      "407/407 [==============================] - 0s 190us/sample - loss: 7.4196e-04 - accuracy: 1.0000 - val_loss: 0.0236 - val_accuracy: 0.9902\n",
      "Epoch 120/200\n",
      "407/407 [==============================] - 0s 242us/sample - loss: 7.0295e-04 - accuracy: 1.0000 - val_loss: 0.0220 - val_accuracy: 0.9902\n",
      "Epoch 121/200\n",
      "407/407 [==============================] - 0s 269us/sample - loss: 7.0449e-04 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 0.9902\n",
      "Epoch 122/200\n",
      "407/407 [==============================] - 0s 252us/sample - loss: 6.7915e-04 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9902\n",
      "Epoch 123/200\n",
      "407/407 [==============================] - 0s 275us/sample - loss: 6.7781e-04 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 0.9902\n",
      "Epoch 124/200\n",
      "407/407 [==============================] - 0s 259us/sample - loss: 6.5583e-04 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 0.9902\n",
      "Epoch 125/200\n",
      "407/407 [==============================] - 0s 246us/sample - loss: 6.4782e-04 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 0.9902\n",
      "Epoch 126/200\n",
      "407/407 [==============================] - 0s 226us/sample - loss: 6.2574e-04 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9902\n",
      "Epoch 127/200\n",
      "407/407 [==============================] - 0s 247us/sample - loss: 6.1299e-04 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 0.9902\n",
      "Epoch 128/200\n",
      "407/407 [==============================] - 0s 250us/sample - loss: 5.9740e-04 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 0.9902\n",
      "Epoch 129/200\n",
      "407/407 [==============================] - 0s 255us/sample - loss: 5.8505e-04 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 0.9902\n",
      "Epoch 130/200\n",
      "407/407 [==============================] - 0s 263us/sample - loss: 5.7618e-04 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 0.9902\n",
      "Epoch 131/200\n",
      "407/407 [==============================] - 0s 261us/sample - loss: 5.7751e-04 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9902\n",
      "Epoch 132/200\n",
      "407/407 [==============================] - 0s 256us/sample - loss: 5.5369e-04 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 0.9804\n",
      "Epoch 133/200\n",
      "407/407 [==============================] - 0s 251us/sample - loss: 5.4554e-04 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 0.9902\n",
      "Epoch 134/200\n",
      "407/407 [==============================] - 0s 254us/sample - loss: 5.3381e-04 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 0.9902\n",
      "Epoch 135/200\n",
      "407/407 [==============================] - 0s 256us/sample - loss: 5.2573e-04 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 0.9902\n",
      "Epoch 136/200\n",
      "407/407 [==============================] - 0s 259us/sample - loss: 5.1199e-04 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 0.9902\n",
      "Epoch 137/200\n",
      "407/407 [==============================] - 0s 241us/sample - loss: 5.1424e-04 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9902\n",
      "Epoch 138/200\n",
      "407/407 [==============================] - 0s 269us/sample - loss: 4.9392e-04 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 0.9902\n",
      "Epoch 139/200\n",
      "407/407 [==============================] - 0s 275us/sample - loss: 4.8534e-04 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 0.9902\n",
      "Epoch 140/200\n",
      "407/407 [==============================] - 0s 291us/sample - loss: 4.7301e-04 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 0.9902\n",
      "Epoch 141/200\n",
      "407/407 [==============================] - 0s 270us/sample - loss: 4.7583e-04 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 0.9902\n",
      "Epoch 142/200\n",
      "407/407 [==============================] - 0s 268us/sample - loss: 4.6869e-04 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 0.9804\n",
      "Epoch 143/200\n",
      "407/407 [==============================] - 0s 275us/sample - loss: 4.6822e-04 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9902\n",
      "Epoch 144/200\n",
      "407/407 [==============================] - 0s 275us/sample - loss: 4.3983e-04 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 0.9902\n",
      "Epoch 145/200\n",
      "407/407 [==============================] - 0s 261us/sample - loss: 4.3803e-04 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 0.9902\n",
      "Epoch 146/200\n",
      "407/407 [==============================] - 0s 268us/sample - loss: 4.3263e-04 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 0.9902\n",
      "Epoch 147/200\n",
      "407/407 [==============================] - 0s 254us/sample - loss: 4.1495e-04 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9902\n",
      "Epoch 148/200\n",
      "407/407 [==============================] - 0s 265us/sample - loss: 4.1597e-04 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9902\n",
      "Epoch 149/200\n",
      "407/407 [==============================] - 0s 259us/sample - loss: 4.0065e-04 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 0.9902\n",
      "Epoch 150/200\n",
      "407/407 [==============================] - 0s 260us/sample - loss: 3.9782e-04 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9902\n",
      "Epoch 151/200\n",
      "407/407 [==============================] - 0s 255us/sample - loss: 3.9865e-04 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 0.9902\n",
      "Epoch 152/200\n",
      "407/407 [==============================] - 0s 256us/sample - loss: 3.8948e-04 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 0.9804\n",
      "Epoch 153/200\n",
      "407/407 [==============================] - 0s 278us/sample - loss: 3.7626e-04 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 0.9902\n",
      "Epoch 154/200\n",
      "407/407 [==============================] - 0s 275us/sample - loss: 3.8177e-04 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 0.9902\n",
      "Epoch 155/200\n",
      "407/407 [==============================] - 0s 274us/sample - loss: 3.6646e-04 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 0.9902\n",
      "Epoch 156/200\n",
      "407/407 [==============================] - 0s 265us/sample - loss: 3.5661e-04 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 0.9902\n",
      "Epoch 157/200\n",
      "407/407 [==============================] - 0s 271us/sample - loss: 3.5100e-04 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 0.9902\n",
      "Epoch 158/200\n",
      "407/407 [==============================] - 0s 277us/sample - loss: 3.4787e-04 - accuracy: 1.0000 - val_loss: 0.0220 - val_accuracy: 0.9902\n",
      "Epoch 159/200\n",
      "407/407 [==============================] - 0s 260us/sample - loss: 3.3999e-04 - accuracy: 1.0000 - val_loss: 0.0220 - val_accuracy: 0.9902\n",
      "Epoch 160/200\n",
      "407/407 [==============================] - 0s 260us/sample - loss: 3.3587e-04 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 0.9902\n",
      "Epoch 161/200\n",
      "407/407 [==============================] - 0s 247us/sample - loss: 3.2894e-04 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 0.9902\n",
      "Epoch 162/200\n",
      "407/407 [==============================] - 0s 265us/sample - loss: 3.2642e-04 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 0.9804\n",
      "Epoch 163/200\n",
      "407/407 [==============================] - 0s 239us/sample - loss: 3.1995e-04 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 0.9902\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407/407 [==============================] - 0s 248us/sample - loss: 3.2007e-04 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 0.9902\n",
      "Epoch 165/200\n",
      "407/407 [==============================] - 0s 246us/sample - loss: 3.0710e-04 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 0.9902\n",
      "Epoch 166/200\n",
      "407/407 [==============================] - 0s 238us/sample - loss: 3.0570e-04 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 0.9804\n",
      "Epoch 167/200\n",
      "407/407 [==============================] - 0s 224us/sample - loss: 2.9752e-04 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 0.9902\n",
      "Epoch 00167: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1748daa97c8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs = 200, validation_data = (X_test, y_test), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.658812</td>\n",
       "      <td>0.552826</td>\n",
       "      <td>0.613332</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.607452</td>\n",
       "      <td>0.660934</td>\n",
       "      <td>0.560091</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.555916</td>\n",
       "      <td>0.724816</td>\n",
       "      <td>0.499886</td>\n",
       "      <td>0.784314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.490180</td>\n",
       "      <td>0.830467</td>\n",
       "      <td>0.431154</td>\n",
       "      <td>0.843137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.419153</td>\n",
       "      <td>0.872236</td>\n",
       "      <td>0.360944</td>\n",
       "      <td>0.911765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  0.658812  0.552826  0.613332      0.617647\n",
       "1  0.607452  0.660934  0.560091      0.705882\n",
       "2  0.555916  0.724816  0.499886      0.784314\n",
       "3  0.490180  0.830467  0.431154      0.843137\n",
       "4  0.419153  0.872236  0.360944      0.911765"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1748ee5c048>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## THIS IS PERFECT \n",
    "model_history.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 164us/sample - loss: 0.0225 - accuracy: 0.9902\n",
      "0.02248360982333657 0.99019605\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_test, y_test)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\emreo\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: autism_screener\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('autism_screener')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model('autism_screener')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = new_model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47  1]\n",
      " [ 0 54]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        48\n",
      "           1       0.98      1.00      0.99        54\n",
      "\n",
      "    accuracy                           0.99       102\n",
      "   macro avg       0.99      0.99      0.99       102\n",
      "weighted avg       0.99      0.99      0.99       102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9901960784313726\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
